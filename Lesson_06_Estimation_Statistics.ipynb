{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson 06 - Estimation Statistics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3o2T6+be130XksgHjcey2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/finesketch/statistics/blob/main/Lesson_06_Estimation_Statistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr-Q9vTChuo4"
      },
      "source": [
        "In addition to the statistical hypothesis tests, one can use estimation statistics for testing the sample significance.\n",
        "\n",
        "Statistical hypothesis tests can be used to indicate whether the difference between two samples is due to random chance, but it cannot tell on the size of the difference.\n",
        "\n",
        "Estimation statistics is a term to describe three main classes of methods:\n",
        "\n",
        "* **Effect Size**: Methods for quantifying the size of an effect given a treatment or intervention.\n",
        "* **Interval Estimation**: Methods for quantifying the amount of uncertainty in a value.\n",
        "* **Meta-Analysis**: Methods for quantifying the findings across multiple similiar studies. \n",
        "\n",
        "In addition, there are three types of *intervals*:\n",
        "\n",
        "* **Tolerance Interval**: The builds of a proportion of a distribution with a specific level of confidence.\n",
        "* **Confidence Interval**: The bounds on the estimate of a population parameter.\n",
        "* **Prediction Interval**: The builds on a single observation.\n",
        "\n",
        "A simple way to calculate a confidence interval for a classification algorithm is to calculate the *binomial* proportion confidence interval, which can provide an interval around a model's estimated accuracy or error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rsskq-TkHWO",
        "outputId": "a4b31edd-dcbd-4703-faad-72303136fd48"
      },
      "source": [
        "# this example demostrates the \"proportion_confint\" function in a hypothical case where a model\n",
        "# made 88 correct predictions out of a dataset with 100 instances and we interested in the 95% confidence interval \n",
        "# (provided to the function as a significance of 0.05)\n",
        "\n",
        "# calculate the confidence interval \n",
        "from statsmodels.stats.proportion import proportion_confint\n",
        "\n",
        "# calculate the interval\n",
        "lower, upper = proportion_confint(88, 100, 0.05)\n",
        "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
        "# output: lower=0.816, upper=0.944\n",
        "\n",
        "lower, upper = proportion_confint(90, 100, 0.05)\n",
        "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
        "# output: lower=0.841, upper=0.959\n",
        "\n",
        "lower, upper = proportion_confint(65, 100, 0.05)\n",
        "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
        "# output: lower=0.557, upper=0.743\n",
        "\n",
        "lower, upper = proportion_confint(75, 100, 0.05)\n",
        "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
        "# output: lower=0.665, upper=0.835\n",
        "\n",
        "lower, upper = proportion_confint(85, 100, 0.05)\n",
        "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
        "# output: lower=0.780, upper=0.920\n",
        "\n",
        "lower, upper = proportion_confint(100, 100, 0.05)\n",
        "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
        "# output: lower=1.000, upper=1.000\n",
        "\n",
        "lower, upper = proportion_confint(95, 100, 0.05)\n",
        "print('lower=%.3f, upper=%.3f' % (lower, upper))\n",
        "# output: lower=0.907, upper=0.993\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lower=0.816, upper=0.944\n",
            "lower=0.841, upper=0.959\n",
            "lower=0.557, upper=0.743\n",
            "lower=0.665, upper=0.835\n",
            "lower=0.780, upper=0.920\n",
            "lower=1.000, upper=1.000\n",
            "lower=0.907, upper=0.993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuS_BpZpmQeV"
      },
      "source": [
        "Tasks\n",
        "\n",
        "Methods used to check for the relationship between variables:\n",
        "* Pearson's Coefficient of Determination (R2)\n",
        "\n",
        "Methods used to check for differences between samples:\n",
        "* Cohen's Odd Ratio (OR)\n",
        "* Cohen's Effect Size\n",
        "* Pearson's Correlation (R)\n",
        "* Relative Risk Ratio (RR)\n",
        "\n",
        "\n",
        "Source: https://machinelearningmastery.com/statistics-for-machine-learning-mini-course/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WYalCNJhvUd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}